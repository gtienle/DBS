{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Projekt/elecNH.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = open(\"../Projekt/elecNH .txt\",\"r\")\n",
    "#for line in df:\n",
    "#    print(line.rstrip())\n",
    "#df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagset = []\n",
    "for index, row in df.iterrows():\n",
    "    pattern = row['text']\n",
    "#    p = '#'\n",
    "    if p is None:\n",
    "        print pattern\n",
    "    else:\n",
    "        if p: #Finde Moleküle mit Übereinstimmungen\n",
    "            hashtagset.append(pattern)#Füge das Pattern als SMARTS-String in das patternset\n",
    "\n",
    "#print 'length',len(hashtagset)\n",
    "#print 'hashtags', hashtagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start process_tweet\n",
    "def processTweet(hashtag):\n",
    "    # process the tweets\n",
    "\n",
    "    #Convert to lower case\n",
    "    hashtag = hashtag.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    hashtag = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',hashtag)\n",
    "    #Convert @username to AT_USER\n",
    "    hashtag = re.sub('@[^\\s]+','AT_USER',hashtag)\n",
    "    #Remove additional white spaces\n",
    "    hashtag = re.sub('[\\s]+', ' ', hashtag)\n",
    "    #Replace #word with word\n",
    "    hashtag = re.sub(r'#([^\\s]+)', r'\\1', hashtag)\n",
    "    #trim\n",
    "    hashtag = hashtag.strip('\\'\"')\n",
    "    return hashtag \n",
    "#end\n",
    "\n",
    "#Read the tweets one by one and process it\n",
    "fp = open('elecNH.csv', 'r')\n",
    "line = fp.readline()\n",
    "\n",
    "while line:\n",
    "    processedTweet = processTweet(line)\n",
    "#    print 'length',len(processedTweet)\n",
    "#    print processedTweet\n",
    "    line = fp.readline()\n",
    "#end loop\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 1L, 'HillaryClinton', 'The question in this election: Who can put the plans into action that will make your life better? https://t.co/XreEY9OicG', False, nan, '2016-09-28T00:22:34', 218L, 651L, ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-2fbcfa4685d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# write the modified row to the output csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Praktikum\\Anaconda2\\lib\\csv.pyc\u001b[0m in \u001b[0;36mwriterow\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Praktikum\\Anaconda2\\lib\\csv.pyc\u001b[0m in \u001b[0;36m_dict_to_list\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrong_fields\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 raise ValueError(\"dict contains fields not in fieldnames: \"\n\u001b[1;32m--> 148\u001b[1;33m                                  + \", \".join([repr(x) for x in wrong_fields]))\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dict contains fields not in fieldnames: 1L, 'HillaryClinton', 'The question in this election: Who can put the plans into action that will make your life better? https://t.co/XreEY9OicG', False, nan, '2016-09-28T00:22:34', 218L, 651L, ''"
     ]
    }
   ],
   "source": [
    "with open('elecNH.csv', 'r') as csv_in, open('results.csv', 'w') as csv_out:\n",
    "    # The reader will figure out the field names \n",
    "    # based on the first line in the file.\n",
    "    reader = csv.DictReader(\n",
    "        csv_in\n",
    "    )\n",
    "    # We have to tell the writer the fields and their order\n",
    "    # and which dialect of csv we want. \n",
    "    writer = csv.DictWriter(\n",
    "        csv_out, \n",
    "        fieldnames=reader.fieldnames + ['hashtags'],\n",
    "        dialect=reader.dialect,\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "    )\n",
    "    # write the header line of the output csv\n",
    "    writer.writeheader()\n",
    "\n",
    "    # loop over each line in the csv. The header line is not \n",
    "    # part of this loop when using csv.DictReader\n",
    "    for index, row in df.iterrows():\n",
    "        # Split the tweet into words using str.split()\n",
    "        words = row['text'].split()\n",
    "\n",
    "        # If you need to modify this code, you should turn the \n",
    "        # following lines into one or two separate functions.\n",
    "        # This will make debugging and testing easier.\n",
    "\n",
    "        # Filter and join the words using str.startswith()\n",
    "        row['text'] = ' '.join(\n",
    "            w for w in words if not w.startswith('#'))\n",
    "\n",
    "        # Extract the hashtags and remove the initial \"#\"\n",
    "        # using string slicing.\n",
    "        row['hashtags'] = ','.join(\n",
    "            w[1:] for w in words if w.startswith('#'))\n",
    "\n",
    "        # write the modified row to the output csv\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hashtags []\n"
     ]
    }
   ],
   "source": [
    "#mol = Chem.MolFromSmiles('C1(CCOS(=O)(=O)C(F)(F)F)(CO)SC(C(=O)O)=C(C(=O)O)S1') #Beispielmolekül, das getestet wird\n",
    "patternset = [] #erstellen Liste patternset\n",
    "for index, row in df.iterrows(): #speichert die Zeile und können so auf Smarts zugreifen\n",
    "    pattern = row['text'] #speichern die SMARTS-Strings in pattern\n",
    "#    compound = row['NAMES']\n",
    "#    p = Chem.MolFromSmarts(pattern) #Molekülpattern und speichern in p\n",
    "\n",
    "print 'hashtags', patternset\n",
    "#print 'name' , compoundset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
